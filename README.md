# Financial QA System: RAG vs Fine-Tuning

This project implements and compares two approaches for answering questions about Allstate's financial reports:
1. **Retrieval-Augmented Generation (RAG)**: Combines hybrid document retrieval with generative language models
2. **Fine-Tuned Language Model (FT)**: Direct fine-tuning of a small language model on financial Q&A

## ğŸš€ Quick Start

### Model Files
Due to file size limitations, model files are not included in this repository. To use the system:

1. Download the fine-tuned model from [Hugging Face Hub](https://huggingface.co/models) (link to be added)
2. Place the downloaded files in the following structure:
   ```
   models/
   â””â”€â”€ fine_tuned_model/
       â”œâ”€â”€ config.json
       â”œâ”€â”€ model.safetensors
       â”œâ”€â”€ tokenizer.json
       â””â”€â”€ ...
   ```

## ğŸŒŸ Key Features

### RAG System
- **Hybrid Retrieval**: 
  - Dense retrieval using Sentence Transformers (all-MiniLM-L6-v2)
  - Sparse retrieval using BM25
  - Score fusion for optimal chunk selection
- **Context-Aware Generation**: 
  - Prompts engineered for financial accuracy
  - Dynamic context window management
  - Multi-chunk answer synthesis

### Fine-Tuned Model
- **Base Model**: DistilGPT2 (small, efficient)
- **Training Data**: 30+ carefully curated financial Q&A pairs
- **Optimization**: Parameter-efficient fine-tuning

### Guardrails
- **Input Validation**:
  - Financial keyword detection
  - Query complexity analysis
  - Minimum length requirements
- **Output Validation**:
  - Confidence scoring
  - Hallucination detection
  - Answer quality metrics

### Evaluation Framework
- Response time tracking
- Confidence scoring
- Chunk relevance metrics
- Answer quality assessment

## ğŸ”§ Setup Instructions (Run Locally)

### 1. Clone the Repository
```bash
git clone <your-repo-url>
cd financial_qa_rag_ft
```

### 2. Create Virtual Environment (optional)
```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Download Financial Reports
```bash
python utils/download_reports.py
```

### 5. Extract and Clean Text
```bash
Run: notebooks/01_data_preprocessing.ipynb
```

### 6. Generate QA Pairs Automatically
```bash
python utils/generate_qa_pairs.py
```

### 7. Train Fine-Tuned Model (Optional)
```bash
Run: notebooks/03_fine_tuning.ipynb
```

### 8. Run Streamlit App
```bash
streamlit run app/app.py
```

---

## ğŸ“‚ Project Structure
```
financial_qa_rag_ft/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py                 # Streamlit web interface with real-time metrics
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/             # Cleaned and segmented text files
â”‚   â”‚   â”œâ”€â”€ Allstate_2022_10K.txt
â”‚   â”‚   â””â”€â”€ Allstate_2023_10K.txt
â”‚   â””â”€â”€ raw/                   # Original financial reports
â”‚       â”œâ”€â”€ Allstate_2022_10K.pdf
â”‚       â””â”€â”€ Allstate_2023_10K.pdf
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ fine_tuned_model/     # DistilGPT2 fine-tuned on financial QA
â”‚   â””â”€â”€ rag_model/            # Saved embeddings and retrieval indices
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_preprocessing.ipynb  # PDF parsing and text cleaning
â”‚   â”œâ”€â”€ 02_rag_pipeline.ipynb       # RAG implementation and testing
â”‚   â”œâ”€â”€ 03_fine_tuning.ipynb       # Model fine-tuning process
â”‚   â”œâ”€â”€ 04_evaluation.ipynb        # Individual model evaluation
â”‚   â””â”€â”€ 05_evaluation_comparison.ipynb  # Comparative analysis
â”œâ”€â”€ qa_pairs/
â”‚   â””â”€â”€ qa_dataset.json       # Curated financial QA pairs
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ chunking.py           # Smart text segmentation
â”‚   â”œâ”€â”€ data_preprocessing.py # PDF processing pipeline
â”‚   â”œâ”€â”€ evaluation.py        # Comprehensive metrics
â”‚   â”œâ”€â”€ fine_tuning.py      # Training utilities
â”‚   â”œâ”€â”€ generator.py        # Answer generation logic
â”‚   â”œâ”€â”€ guardrails.py      # Input/output validation
â”‚   â””â”€â”€ retriever.py       # Hybrid search implementation
â”œâ”€â”€ requirements.txt          # Project dependencies
â””â”€â”€ README.md                # Project documentation
```

---

## ğŸ“Š Performance Comparison

### RAG System
- **Strengths**:
  - Higher factual accuracy
  - Better source traceability
  - More robust to unseen questions
- **Metrics**:
  - Average response time: ~0.5s
  - Typical confidence: 0.8-0.95
  - Strong chunk relevance scores

### Fine-tuned Model
- **Strengths**:
  - Faster inference
  - More natural language
  - Consistent response style
- **Metrics**:
  - Average response time: ~0.4s
  - Typical confidence: 0.75-0.9
  - Good performance on seen patterns

## ğŸ’¡ Example Questions

```python
# High-confidence questions
"What was Allstate's total revenue in 2023?"
"How much was the net loss in 2023?"
"What were the total assets in 2022?"

# Complex analytical questions
"How did revenue change from 2022 to 2023?"
"What factors affected profitability in 2023?"
"Compare the investment portfolio returns between 2022 and 2023"
```

## ğŸ› ï¸ Technical Requirements

- Python 3.8+
- PyTorch 2.0+
- Transformers 4.31+
- Streamlit 1.24+
- Sentence-Transformers 2.2+
- See requirements.txt for full list

## ï¿½ License
This project is for academic/educational use only. Financial data sourced from Allstate's public reports.

## ğŸ™ Acknowledgments
- Built using Hugging Face Transformers
- Financial data from Allstate's 10-K reports
- Streamlit for the web interface
